{"ast":null,"code":"import _asyncToGenerator from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _construct from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/construct\";\nimport _slicedToArray from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _classCallCheck from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/home/aurimas/coding/idendro/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, $Symbol = \"function\" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || \"@@iterator\", asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\", toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, \"\"); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return generator._invoke = function (innerFn, self, context) { var state = \"suspendedStart\"; return function (method, arg) { if (\"executing\" === state) throw new Error(\"Generator is already running\"); if (\"completed\" === state) { if (\"throw\" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if (\"next\" === context.method) context.sent = context._sent = context.arg;else if (\"throw\" === context.method) { if (\"suspendedStart\" === state) throw state = \"completed\", context.arg; context.dispatchException(context.arg); } else \"return\" === context.method && context.abrupt(\"return\", context.arg); state = \"executing\"; var record = tryCatch(innerFn, self, context); if (\"normal\" === record.type) { if (state = context.done ? \"completed\" : \"suspendedYield\", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } \"throw\" === record.type && (state = \"completed\", context.method = \"throw\", context.arg = record.arg); } }; }(innerFn, self, context), generator; } function tryCatch(fn, obj, arg) { try { return { type: \"normal\", arg: fn.call(obj, arg) }; } catch (err) { return { type: \"throw\", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { [\"next\", \"throw\", \"return\"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if (\"throw\" !== record.type) { var result = record.arg, value = result.value; return value && \"object\" == typeof value && hasOwn.call(value, \"__await\") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke(\"next\", value, resolve, reject); }, function (err) { invoke(\"throw\", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke(\"throw\", error, resolve, reject); }); } reject(record.arg); } var previousPromise; this._invoke = function (method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); }; } function maybeInvokeDelegate(delegate, context) { var method = delegate.iterator[context.method]; if (undefined === method) { if (context.delegate = null, \"throw\" === context.method) { if (delegate.iterator.return && (context.method = \"return\", context.arg = undefined, maybeInvokeDelegate(delegate, context), \"throw\" === context.method)) return ContinueSentinel; context.method = \"throw\", context.arg = new TypeError(\"The iterator does not provide a 'throw' method\"); } return ContinueSentinel; } var record = tryCatch(method, delegate.iterator, context.arg); if (\"throw\" === record.type) return context.method = \"throw\", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, \"return\" !== context.method && (context.method = \"next\", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = \"throw\", context.arg = new TypeError(\"iterator result is not an object\"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = \"normal\", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: \"root\" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if (\"function\" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) { if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; } return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, define(Gp, \"constructor\", GeneratorFunctionPrototype), define(GeneratorFunctionPrototype, \"constructor\", GeneratorFunction), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, \"GeneratorFunction\"), exports.isGeneratorFunction = function (genFun) { var ctor = \"function\" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || \"GeneratorFunction\" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, \"GeneratorFunction\")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, \"Generator\"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, \"toString\", function () { return \"[object Generator]\"; }), exports.keys = function (object) { var keys = []; for (var key in object) { keys.push(key); } return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) { \"t\" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); } }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if (\"throw\" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = \"throw\", record.arg = exception, context.next = loc, caught && (context.method = \"next\", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if (\"root\" === entry.tryLoc) return handle(\"end\"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, \"catchLoc\"), hasFinally = hasOwn.call(entry, \"finallyLoc\"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error(\"try statement without catch or finally\"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, \"finallyLoc\") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && (\"break\" === type || \"continue\" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = \"next\", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if (\"throw\" === record.type) throw record.arg; return \"break\" === record.type || \"continue\" === record.type ? this.next = record.arg : \"return\" === record.type ? (this.rval = this.arg = record.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, catch: function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if (\"throw\" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, \"next\" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }\n\nfunction _asyncIterator(iterable) { var method, async, sync, retry = 2; for (\"undefined\" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;) { if (async && null != (method = iterable[async])) return method.call(iterable); if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator(method.call(iterable)); async = \"@@asyncIterator\", sync = \"@@iterator\"; } throw new TypeError(\"Object is not async iterable\"); }\n\nfunction AsyncFromSyncIterator(s) { function AsyncFromSyncIteratorContinuation(r) { if (Object(r) !== r) return Promise.reject(new TypeError(r + \" is not an object.\")); var done = r.done; return Promise.resolve(r.value).then(function (value) { return { value: value, done: done }; }); } return AsyncFromSyncIterator = function AsyncFromSyncIterator(s) { this.s = s, this.n = s.next; }, AsyncFromSyncIterator.prototype = { s: null, n: null, next: function next() { return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments)); }, return: function _return(value) { var ret = this.s.return; return void 0 === ret ? Promise.resolve({ value: value, done: !0 }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments)); }, throw: function _throw(value) { var thr = this.s.return; return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments)); } }, new AsyncFromSyncIterator(s); }\n\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Column } from './column';\nimport { Schema } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { RecordBatchReader } from './ipc/reader';\nimport { Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Chunked, StructVector } from './vector/index';\nexport var Table = /*#__PURE__*/function (_Chunked) {\n  _inherits(Table, _Chunked);\n\n  var _super = _createSuper(Table);\n\n  function Table() {\n    var _this;\n\n    _classCallCheck(this, Table);\n\n    var schema = null;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    if (args[0] instanceof Schema) {\n      schema = args.shift();\n    }\n\n    var chunks = selectArgs(RecordBatch, args);\n\n    if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n      throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n    }\n\n    chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n    _this = _super.call(this, new Struct(schema.fields), chunks);\n    _this._schema = schema;\n    _this._chunks = chunks;\n    return _this;\n  }\n  /** @nocollapse */\n\n\n  _createClass(Table, [{\n    key: \"schema\",\n    get: function get() {\n      return this._schema;\n    }\n  }, {\n    key: \"length\",\n    get: function get() {\n      return this._length;\n    }\n  }, {\n    key: \"chunks\",\n    get: function get() {\n      return this._chunks;\n    }\n  }, {\n    key: \"numCols\",\n    get: function get() {\n      return this._numChildren;\n    }\n  }, {\n    key: \"clone\",\n    value: function clone() {\n      var chunks = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._chunks;\n      return new Table(this._schema, chunks);\n    }\n  }, {\n    key: \"getColumn\",\n    value: function getColumn(name) {\n      return this.getColumnAt(this.getColumnIndex(name));\n    }\n  }, {\n    key: \"getColumnAt\",\n    value: function getColumnAt(index) {\n      return this.getChildAt(index);\n    }\n  }, {\n    key: \"getColumnIndex\",\n    value: function getColumnIndex(name) {\n      return this._schema.fields.findIndex(function (f) {\n        return f.name === name;\n      });\n    }\n  }, {\n    key: \"getChildAt\",\n    value: function getChildAt(index) {\n      if (index < 0 || index >= this.numChildren) {\n        return null;\n      }\n\n      var field, child;\n      var fields = this._schema.fields;\n      var columns = this._children || (this._children = []);\n\n      if (child = columns[index]) {\n        return child;\n      }\n\n      if (field = fields[index]) {\n        var chunks = this._chunks.map(function (chunk) {\n          return chunk.getChildAt(index);\n        }).filter(function (vec) {\n          return vec != null;\n        });\n\n        if (chunks.length > 0) {\n          return columns[index] = new Column(field, chunks);\n        }\n      }\n\n      return null;\n    } // @ts-ignore\n\n  }, {\n    key: \"serialize\",\n    value: function serialize() {\n      var encoding = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 'binary';\n      var stream = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      var Writer = !stream ? RecordBatchFileWriter : RecordBatchStreamWriter;\n      return Writer.writeAll(this).toUint8Array(true);\n    }\n  }, {\n    key: \"count\",\n    value: function count() {\n      return this._length;\n    }\n  }, {\n    key: \"select\",\n    value: function select() {\n      var nameToIndex = this._schema.fields.reduce(function (m, f, i) {\n        return m.set(f.name, i);\n      }, new Map());\n\n      for (var _len2 = arguments.length, columnNames = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n        columnNames[_key2] = arguments[_key2];\n      }\n\n      return this.selectAt.apply(this, _toConsumableArray(columnNames.map(function (columnName) {\n        return nameToIndex.get(columnName);\n      }).filter(function (x) {\n        return x > -1;\n      })));\n    }\n  }, {\n    key: \"selectAt\",\n    value: function selectAt() {\n      var _this$_schema;\n\n      for (var _len3 = arguments.length, columnIndices = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n        columnIndices[_key3] = arguments[_key3];\n      }\n\n      var schema = (_this$_schema = this._schema).selectAt.apply(_this$_schema, columnIndices);\n\n      return new Table(schema, this._chunks.map(function (_ref) {\n        var length = _ref.length,\n            childData = _ref.data.childData;\n        return new RecordBatch(schema, length, columnIndices.map(function (i) {\n          return childData[i];\n        }).filter(Boolean));\n      }));\n    }\n  }, {\n    key: \"assign\",\n    value: function assign(other) {\n      var _this2 = this;\n\n      var fields = this._schema.fields;\n\n      var _other$schema$fields$ = other.schema.fields.reduce(function (memo, f2, newIdx) {\n        var _memo = _slicedToArray(memo, 2),\n            indices = _memo[0],\n            oldToNew = _memo[1];\n\n        var i = fields.findIndex(function (f) {\n          return f.name === f2.name;\n        });\n        ~i ? oldToNew[i] = newIdx : indices.push(newIdx);\n        return memo;\n      }, [[], []]),\n          _other$schema$fields$2 = _slicedToArray(_other$schema$fields$, 2),\n          indices = _other$schema$fields$2[0],\n          oldToNew = _other$schema$fields$2[1];\n\n      var schema = this._schema.assign(other.schema);\n\n      var columns = [].concat(_toConsumableArray(fields.map(function (_f, i, _fs) {\n        var j = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : oldToNew[i];\n        return j === undefined ? _this2.getColumnAt(i) : other.getColumnAt(j);\n      })), _toConsumableArray(indices.map(function (i) {\n        return other.getColumnAt(i);\n      }))).filter(Boolean);\n      return _construct(Table, _toConsumableArray(distributeVectorsIntoRecordBatches(schema, columns)));\n    }\n  }], [{\n    key: \"empty\",\n    value: function empty() {\n      var schema = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : new Schema([]);\n      return new Table(schema, []);\n    }\n    /** @nocollapse */\n\n  }, {\n    key: \"from\",\n    value: function from(input) {\n      if (!input) {\n        return Table.empty();\n      }\n\n      if (typeof input === 'object') {\n        var table = isIterable(input['values']) ? tableFromIterable(input) : isAsyncIterable(input['values']) ? tableFromAsyncIterable(input) : null;\n\n        if (table !== null) {\n          return table;\n        }\n      }\n\n      var reader = RecordBatchReader.from(input);\n\n      if (isPromise(reader)) {\n        return _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n          return _regeneratorRuntime().wrap(function _callee$(_context) {\n            while (1) {\n              switch (_context.prev = _context.next) {\n                case 0:\n                  _context.t0 = Table;\n                  _context.next = 3;\n                  return reader;\n\n                case 3:\n                  _context.t1 = _context.sent;\n                  _context.next = 6;\n                  return _context.t0.from.call(_context.t0, _context.t1);\n\n                case 6:\n                  return _context.abrupt(\"return\", _context.sent);\n\n                case 7:\n                case \"end\":\n                  return _context.stop();\n              }\n            }\n          }, _callee);\n        }))();\n      }\n\n      if (reader.isSync() && (reader = reader.open())) {\n        return !reader.schema ? Table.empty() : new Table(reader.schema, _toConsumableArray(reader));\n      }\n\n      return function () {\n        var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(opening) {\n          var reader, schema, batches, _iteratorAbruptCompletion, _didIteratorError, _iteratorError, _iterator, _step, batch;\n\n          return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n            while (1) {\n              switch (_context2.prev = _context2.next) {\n                case 0:\n                  _context2.next = 2;\n                  return opening;\n\n                case 2:\n                  reader = _context2.sent;\n                  schema = reader.schema;\n                  batches = [];\n\n                  if (!schema) {\n                    _context2.next = 35;\n                    break;\n                  }\n\n                  _iteratorAbruptCompletion = false;\n                  _didIteratorError = false;\n                  _context2.prev = 8;\n                  _iterator = _asyncIterator(reader);\n\n                case 10:\n                  _context2.next = 12;\n                  return _iterator.next();\n\n                case 12:\n                  if (!(_iteratorAbruptCompletion = !(_step = _context2.sent).done)) {\n                    _context2.next = 18;\n                    break;\n                  }\n\n                  batch = _step.value;\n                  batches.push(batch);\n\n                case 15:\n                  _iteratorAbruptCompletion = false;\n                  _context2.next = 10;\n                  break;\n\n                case 18:\n                  _context2.next = 24;\n                  break;\n\n                case 20:\n                  _context2.prev = 20;\n                  _context2.t0 = _context2[\"catch\"](8);\n                  _didIteratorError = true;\n                  _iteratorError = _context2.t0;\n\n                case 24:\n                  _context2.prev = 24;\n                  _context2.prev = 25;\n\n                  if (!(_iteratorAbruptCompletion && _iterator.return != null)) {\n                    _context2.next = 29;\n                    break;\n                  }\n\n                  _context2.next = 29;\n                  return _iterator.return();\n\n                case 29:\n                  _context2.prev = 29;\n\n                  if (!_didIteratorError) {\n                    _context2.next = 32;\n                    break;\n                  }\n\n                  throw _iteratorError;\n\n                case 32:\n                  return _context2.finish(29);\n\n                case 33:\n                  return _context2.finish(24);\n\n                case 34:\n                  return _context2.abrupt(\"return\", new Table(schema, batches));\n\n                case 35:\n                  return _context2.abrupt(\"return\", Table.empty());\n\n                case 36:\n                case \"end\":\n                  return _context2.stop();\n              }\n            }\n          }, _callee2, null, [[8, 20, 24, 34], [25,, 29, 33]]);\n        }));\n\n        return function (_x) {\n          return _ref3.apply(this, arguments);\n        };\n      }()(reader.open());\n    }\n    /** @nocollapse */\n\n  }, {\n    key: \"fromAsync\",\n    value: function () {\n      var _fromAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(source) {\n        return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                _context3.next = 2;\n                return Table.from(source);\n\n              case 2:\n                return _context3.abrupt(\"return\", _context3.sent);\n\n              case 3:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3);\n      }));\n\n      function fromAsync(_x2) {\n        return _fromAsync.apply(this, arguments);\n      }\n\n      return fromAsync;\n    }()\n    /** @nocollapse */\n\n  }, {\n    key: \"fromStruct\",\n    value: function fromStruct(vector) {\n      return Table.new(vector.data.childData, vector.type.children);\n    }\n    /** @nocollapse */\n\n  }, {\n    key: \"new\",\n    value: function _new() {\n      for (var _len4 = arguments.length, cols = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n        cols[_key4] = arguments[_key4];\n      }\n\n      return _construct(Table, _toConsumableArray(distributeColumnsIntoRecordBatches(selectColumnArgs(cols))));\n    }\n  }]);\n\n  return Table;\n}(Chunked);\n\nfunction tableFromIterable(input) {\n  var type = input.type;\n\n  if (type instanceof Struct) {\n    return Table.fromStruct(StructVector.from(input));\n  }\n\n  return null;\n}\n\nfunction tableFromAsyncIterable(input) {\n  var type = input.type;\n\n  if (type instanceof Struct) {\n    return StructVector.from(input).then(function (vector) {\n      return Table.fromStruct(vector);\n    });\n  }\n\n  return null;\n}","map":{"version":3,"sources":["table.ts"],"names":[],"mappings":";;;;;;;;;+CACA,oJ;;;;;;AADA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA,SAAS,MAAT,QAAuB,UAAvB;AACA,SAAS,MAAT,QAA8B,UAA9B;AACA,SAAS,WAAT,EAAsB,oCAAtB,QAAkE,eAAlE;AAEA,SAAS,iBAAT,QAAkC,cAAlC;AACA,SAA4B,MAA5B,QAA0C,QAA1C;AACA,SAAS,gBAAT,EAA2B,UAA3B,QAA6C,aAA7C;AAEA,SAAS,SAAT,EAAoB,UAApB,EAAgC,eAAhC,QAAuD,eAAvD;AACA,SAAS,qBAAT,EAAgC,uBAAhC,QAA+D,cAA/D;AACA,SAAS,kCAAT,EAA6C,kCAA7C,QAAuF,oBAAvF;AACA,SAAiB,OAAjB,EAA0B,YAA1B,QAA+F,gBAA/F;AAsBA,WAAa,KAAb;EAAA;;EAAA;;EA+HI,iBAA0B;IAAA;;IAAA;;IAEtB,IAAI,MAAM,GAAc,IAAxB;;IAFsB,kCAAX,IAAW;MAAX,IAAW;IAAA;;IAItB,IAAI,IAAI,CAAC,CAAD,CAAJ,YAAmB,MAAvB,EAA+B;MAAE,MAAM,GAAG,IAAI,CAAC,KAAL,EAAT;IAAwB;;IAEzD,IAAI,MAAM,GAAG,UAAU,CAAiB,WAAjB,EAA8B,IAA9B,CAAvB;;IAEA,IAAI,CAAC,MAAD,IAAW,EAAE,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,IAAa,MAAM,CAAC,CAAD,CAAN,CAAU,MAAlC,CAAf,EAA0D;MACtD,MAAM,IAAI,SAAJ,CAAc,qEAAd,CAAN;IACH;;IAED,MAAM,CAAC,CAAD,CAAN,KAAc,MAAM,CAAC,CAAD,CAAN,GAAY,IAAI,oCAAJ,CAAyC,MAAzC,CAA1B;IAEA,0BAAM,IAAI,MAAJ,CAAW,MAAM,CAAC,MAAlB,CAAN,EAAiC,MAAjC;IAEA,MAAK,OAAL,GAAe,MAAf;IACA,MAAK,OAAL,GAAe,MAAf;IAjBsB;EAkBzB;EA1ID;;;EAPJ;IAAA;IAAA,KAwJI,eAAiB;MAAK,OAAO,KAAK,OAAZ;IAAsB;EAxJhD;IAAA;IAAA,KAyJI,eAAiB;MAAK,OAAO,KAAK,OAAZ;IAAsB;EAzJhD;IAAA;IAAA,KA0JI,eAAiB;MAAK,OAAO,KAAK,OAAZ;IAAsB;EA1JhD;IAAA;IAAA,KA2JI,eAAkB;MAAK,OAAO,KAAK,YAAZ;IAA2B;EA3JtD;IAAA;IAAA,OA6JW,iBAA2B;MAAA,IAArB,MAAqB,uEAAZ,KAAK,OAAO;MAC9B,OAAO,IAAI,KAAJ,CAAa,KAAK,OAAlB,EAA2B,MAA3B,CAAP;IACH;EA/JL;IAAA;IAAA,OAiKW,mBAA6B,IAA7B,EAAoC;MACvC,OAAO,KAAK,WAAL,CAAiB,KAAK,cAAL,CAAoB,IAApB,CAAjB,CAAP;IACH;EAnKL;IAAA;IAAA,OAoKW,qBAAsC,KAAtC,EAAmD;MACtD,OAAO,KAAK,UAAL,CAAgB,KAAhB,CAAP;IACH;EAtKL;IAAA;IAAA,OAuKW,wBAAkC,IAAlC,EAAyC;MAC5C,OAAO,KAAK,OAAL,CAAa,MAAb,CAAoB,SAApB,CAA8B,UAAC,CAAD;QAAA,OAAO,CAAC,CAAC,IAAF,KAAW,IAAlB;MAAA,CAA9B,CAAP;IACH;EAzKL;IAAA;IAAA,OA0KW,oBAAqC,KAArC,EAAkD;MACrD,IAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,KAAK,WAA/B,EAA4C;QAAE,OAAO,IAAP;MAAc;;MAC5D,IAAI,KAAJ,EAAqB,KAArB;MACA,IAAM,MAAM,GAAI,KAAK,OAAL,CAA6B,MAA7C;MACA,IAAM,OAAO,GAAG,KAAK,SAAL,KAAmB,KAAK,SAAL,GAAiB,EAApC,CAAhB;;MACA,IAAI,KAAK,GAAG,OAAO,CAAC,KAAD,CAAnB,EAA4B;QAAE,OAAO,KAAP;MAA4B;;MAC1D,IAAI,KAAK,GAAG,MAAM,CAAC,KAAD,CAAlB,EAA2B;QACvB,IAAM,MAAM,GAAG,KAAK,OAAL,CACV,GADU,CACN,UAAC,KAAD;UAAA,OAAW,KAAK,CAAC,UAAN,CAAoB,KAApB,CAAX;QAAA,CADM,EAEV,MAFU,CAEH,UAAC,GAAD;UAAA,OAA2B,GAAG,IAAI,IAAlC;QAAA,CAFG,CAAf;;QAGA,IAAI,MAAM,CAAC,MAAP,GAAgB,CAApB,EAAuB;UACnB,OAAQ,OAAO,CAAC,KAAD,CAAP,GAAiB,IAAI,MAAJ,CAAc,KAAd,EAAqB,MAArB,CAAzB;QACH;MACJ;;MACD,OAAO,IAAP;IACH,CAzLL,CA2LI;;EA3LJ;IAAA;IAAA,OA4LW,qBAA4C;MAAA,IAAlC,QAAkC,uEAAvB,QAAuB;MAAA,IAAb,MAAa,uEAAJ,IAAI;MAC/C,IAAM,MAAM,GAAG,CAAC,MAAD,GACT,qBADS,GAET,uBAFN;MAGA,OAAO,MAAM,CAAC,QAAP,CAAgB,IAAhB,EAAsB,YAAtB,CAAmC,IAAnC,CAAP;IACH;EAjML;IAAA;IAAA,OAkMW,iBAAK;MACR,OAAO,KAAK,OAAZ;IACH;EApML;IAAA;IAAA,OAqMW,kBAAmD;MACtD,IAAM,WAAW,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,MAApB,CAA2B,UAAC,CAAD,EAAI,CAAJ,EAAO,CAAP;QAAA,OAAa,CAAC,CAAC,GAAF,CAAM,CAAC,CAAC,IAAR,EAAmB,CAAnB,CAAb;MAAA,CAA3B,EAA+D,IAAI,GAAJ,EAA/D,CAApB;;MADsD,mCAAhB,WAAgB;QAAhB,WAAgB;MAAA;;MAEtD,OAAO,KAAK,QAAL,gCAAiB,WAAW,CAAC,GAAZ,CAAgB,UAAC,UAAD;QAAA,OAAgB,WAAW,CAAC,GAAZ,CAAgB,UAAhB,CAAhB;MAAA,CAAhB,EAA8D,MAA9D,CAAqE,UAAC,CAAD;QAAA,OAAO,CAAC,GAAG,CAAC,CAAZ;MAAA,CAArE,CAAjB,EAAP;IACH;EAxML;IAAA;IAAA,OAyMW,oBAA+D;MAAA;;MAAA,mCAAvB,aAAuB;QAAvB,aAAuB;MAAA;;MAClE,IAAM,MAAM,GAAG,sBAAK,OAAL,EAAa,QAAb,sBAA4B,aAA5B,CAAf;;MACA,OAAO,IAAI,KAAJ,CAAU,MAAV,EAAkB,KAAK,OAAL,CAAa,GAAb,CAAiB,gBAAoC;QAAA,IAAjC,MAAiC,QAAjC,MAAiC;QAAA,IAAjB,SAAiB,QAAzB,IAAyB,CAAjB,SAAiB;QAC1E,OAAO,IAAI,WAAJ,CAAgB,MAAhB,EAAwB,MAAxB,EAAgC,aAAa,CAAC,GAAd,CAAkB,UAAC,CAAD;UAAA,OAAO,SAAS,CAAC,CAAD,CAAhB;QAAA,CAAlB,EAAuC,MAAvC,CAA8C,OAA9C,CAAhC,CAAP;MACH,CAFwB,CAAlB,CAAP;IAGH;EA9ML;IAAA;IAAA,OA+MW,gBAAoD,KAApD,EAAmE;MAAA;;MAEtE,IAAM,MAAM,GAAG,KAAK,OAAL,CAAa,MAA5B;;MACA,4BAA4B,KAAK,CAAC,MAAN,CAAa,MAAb,CAAoB,MAApB,CAA2B,UAAC,IAAD,EAAO,EAAP,EAAW,MAAX,EAAqB;QACxE,2BAA4B,IAA5B;QAAA,IAAO,OAAP;QAAA,IAAgB,QAAhB;;QACA,IAAM,CAAC,GAAG,MAAM,CAAC,SAAP,CAAiB,UAAC,CAAD;UAAA,OAAO,CAAC,CAAC,IAAF,KAAW,EAAE,CAAC,IAArB;QAAA,CAAjB,CAAV;QACA,CAAC,CAAD,GAAM,QAAQ,CAAC,CAAD,CAAR,GAAc,MAApB,GAA8B,OAAO,CAAC,IAAR,CAAa,MAAb,CAA9B;QACA,OAAO,IAAP;MACH,CAL2B,EAKzB,CAAC,EAAD,EAAK,EAAL,CALyB,CAA5B;MAAA;MAAA,IAAO,OAAP;MAAA,IAAgB,QAAhB;;MAOA,IAAM,MAAM,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,KAAK,CAAC,MAA1B,CAAf;;MACA,IAAM,OAAO,GAAG,6BACT,MAAM,CAAC,GAAP,CAAW,UAAC,EAAD,EAAK,CAAL,EAAQ,GAAR;QAAA,IAAa,CAAb,uEAAiB,QAAQ,CAAC,CAAD,CAAzB;QAAA,OACT,CAAC,KAAK,SAAN,GAAkB,MAAI,CAAC,WAAL,CAAiB,CAAjB,CAAlB,GAAwC,KAAK,CAAC,WAAN,CAAkB,CAAlB,CAD/B;MAAA,CAAX,CADS,sBAGT,OAAO,CAAC,GAAR,CAAY,UAAC,CAAD;QAAA,OAAO,KAAK,CAAC,WAAN,CAAkB,CAAlB,CAAP;MAAA,CAAZ,CAHS,GAId,MAJc,CAIP,OAJO,CAAhB;MAMA,kBAAW,KAAX,qBAA2B,kCAAkC,CAAM,MAAN,EAAc,OAAd,CAA7D;IACH;EAjOL;IAAA;IAAA,OAQW,iBAAmF;MAAA,IAA1B,MAA0B,uEAAjB,IAAI,MAAJ,CAAc,EAAd,CAAiB;MAAI,OAAO,IAAI,KAAJ,CAAa,MAAb,EAAqB,EAArB,CAAP;IAAkC;IAahI;;EArBJ;IAAA;IAAA,OAsBW,cAAsE,KAAtE,EAAiF;MAEpF,IAAI,CAAC,KAAL,EAAY;QAAE,OAAO,KAAK,CAAC,KAAN,EAAP;MAAuB;;MAErC,IAAI,OAAO,KAAP,KAAiB,QAArB,EAA+B;QAC3B,IAAI,KAAK,GAAG,UAAU,CAAC,KAAK,CAAC,QAAD,CAAN,CAAV,GAA8B,iBAAiB,CAAW,KAAX,CAA/C,GACL,eAAe,CAAC,KAAK,CAAC,QAAD,CAAN,CAAf,GAAmC,sBAAsB,CAAW,KAAX,CAAzD,GACmC,IAF1C;;QAGA,IAAI,KAAK,KAAK,IAAd,EAAoB;UAAE,OAAO,KAAP;QAAe;MACxC;;MAED,IAAI,MAAM,GAAG,iBAAiB,CAAC,IAAlB,CAA0B,KAA1B,CAAb;;MAEA,IAAI,SAAS,CAAuB,MAAvB,CAAb,EAA6C;QACzC,OAAO,2DAAC;UAAA;YAAA;cAAA;gBAAA;kBAAA,cAAkB,KAAlB;kBAAA;kBAAA,OAAmC,MAAnC;;gBAAA;kBAAA;kBAAA;kBAAA,mBAAwB,IAAxB;;gBAAA;kBAAA;;gBAAA;gBAAA;kBAAA;cAAA;YAAA;UAAA;QAAA,CAAD,IAAP;MACH;;MACD,IAAI,MAAM,CAAC,MAAP,OAAoB,MAAM,GAAG,MAAM,CAAC,IAAP,EAA7B,CAAJ,EAAiD;QAC7C,OAAO,CAAC,MAAM,CAAC,MAAR,GAAiB,KAAK,CAAC,KAAN,EAAjB,GAAiC,IAAI,KAAJ,CAAa,MAAM,CAAC,MAApB,qBAAgC,MAAhC,EAAxC;MACH;;MACD,OAAO;QAAA,uEAAC,kBAAO,OAAP;UAAA;;UAAA;YAAA;cAAA;gBAAA;kBAAA;kBAAA,OACiB,OADjB;;gBAAA;kBACE,MADF;kBAEE,MAFF,GAEW,MAAM,CAAC,MAFlB;kBAGE,OAHF,GAG2B,EAH3B;;kBAAA,KAIA,MAJA;oBAAA;oBAAA;kBAAA;;kBAAA;kBAAA;kBAAA;kBAAA,2BAKwB,MALxB;;gBAAA;kBAAA;kBAAA;;gBAAA;kBAAA;oBAAA;oBAAA;kBAAA;;kBAKe,KALf;kBAMI,OAAO,CAAC,IAAR,CAAa,KAAb;;gBANJ;kBAAA;kBAAA;kBAAA;;gBAAA;kBAAA;kBAAA;;gBAAA;kBAAA;kBAAA;kBAAA;kBAAA;;gBAAA;kBAAA;kBAAA;;kBAAA;oBAAA;oBAAA;kBAAA;;kBAAA;kBAAA;;gBAAA;kBAAA;;kBAAA;oBAAA;oBAAA;kBAAA;;kBAAA;;gBAAA;kBAAA;;gBAAA;kBAAA;;gBAAA;kBAAA,kCAQO,IAAI,KAAJ,CAAa,MAAb,EAAqB,OAArB,CARP;;gBAAA;kBAAA,kCAUG,KAAK,CAAC,KAAN,EAVH;;gBAAA;gBAAA;kBAAA;cAAA;YAAA;UAAA;QAAA,CAAD;;QAAA;UAAA;QAAA;MAAA,IAWJ,MAAM,CAAC,IAAP,EAXI,CAAP;IAYH;IAED;;EAvDJ;IAAA;IAAA;MAAA,4EAwDW,kBAAoE,MAApE;QAAA;UAAA;YAAA;cAAA;gBAAA;gBAAA,OACU,KAAK,CAAC,IAAN,CAAc,MAAd,CADV;;cAAA;gBAAA;;cAAA;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,CAxDX;;MAAA;QAAA;MAAA;;MAAA;IAAA;IA4DI;;EA5DJ;IAAA;IAAA,OA6DW,oBAA+D,MAA/D,EAAwF;MAC3F,OAAO,KAAK,CAAC,GAAN,CAAa,MAAM,CAAC,IAAP,CAAY,SAAzB,EAA0D,MAAM,CAAC,IAAP,CAAY,QAAtE,CAAP;IACH;IAuDD;;EAtHJ;IAAA;IAAA,OAuHW,gBAAyB;MAAA,mCAAX,IAAW;QAAX,IAAW;MAAA;;MAC5B,kBAAW,KAAX,qBAAoB,kCAAkC,CAAC,gBAAgB,CAAC,IAAD,CAAjB,CAAtD;IACH;EAzHL;;EAAA;AAAA,EACY,OADZ;;AAoOA,SAAS,iBAAT,CAAqF,KAArF,EAAkI;EAC9H,IAAQ,IAAR,GAAiB,KAAjB,CAAQ,IAAR;;EACA,IAAI,IAAI,YAAY,MAApB,EAA4B;IACxB,OAAO,KAAK,CAAC,UAAN,CAAiB,YAAY,CAAC,IAAb,CAAkB,KAAlB,CAAjB,CAAP;EACH;;EACD,OAAO,IAAP;AACH;;AAED,SAAS,sBAAT,CAA0F,KAA1F,EAA4I;EACxI,IAAQ,IAAR,GAAiB,KAAjB,CAAQ,IAAR;;EACA,IAAI,IAAI,YAAY,MAApB,EAA4B;IACxB,OAAO,YAAY,CAAC,IAAb,CAAkB,KAAlB,EAAwE,IAAxE,CAA6E,UAAC,MAAD;MAAA,OAAY,KAAK,CAAC,UAAN,CAAiB,MAAjB,CAAZ;IAAA,CAA7E,CAAP;EACH;;EACD,OAAO,IAAP;AACH","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from './data';\nimport { Column } from './column';\nimport { Schema, Field } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { DataFrame } from './compute/dataframe';\nimport { RecordBatchReader } from './ipc/reader';\nimport { DataType, RowLike, Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { Clonable, Sliceable, Applicative } from './vector';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Vector, Chunked, StructVector, VectorBuilderOptions, VectorBuilderOptionsAsync } from './vector/index';\n\ntype VectorMap = { [key: string]: Vector };\ntype Fields<T extends { [key: string]: DataType }> = (keyof T)[] | Field<T[keyof T]>[];\ntype ChildData<T extends { [key: string]: DataType }> = Data<T[keyof T]>[] | Vector<T[keyof T]>[];\ntype Columns<T extends { [key: string]: DataType }> = Column<T[keyof T]>[] | Column<T[keyof T]>[][];\n\nexport interface Table<T extends { [key: string]: DataType } = any> {\n\n    get(index: number): Struct<T>['TValue'];\n    [Symbol.iterator](): IterableIterator<RowLike<T>>;\n\n    slice(begin?: number, end?: number): Table<T>;\n    concat(...others: Vector<Struct<T>>[]): Table<T>;\n    clone(chunks?: RecordBatch<T>[], offsets?: Uint32Array): Table<T>;\n\n    scan(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    scanReverse(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    countBy(name: import('./compute/predicate').Col | string): import('./compute/dataframe').CountByResult;\n    filter(predicate: import('./compute/predicate').Predicate): import('./compute/dataframe').FilteredDataFrame<T>;\n}\n\nexport class Table<T extends { [key: string]: DataType } = any>\n    extends Chunked<Struct<T>>\n    implements DataFrame<T>,\n               Clonable<Table<T>>,\n               Sliceable<Table<T>>,\n               Applicative<Struct<T>, Table<T>> {\n\n    /** @nocollapse */\n    public static empty<T extends { [key: string]: DataType } = {}>(schema = new Schema<T>([])) { return new Table<T>(schema, []); }\n\n    public static from(): Table<{}>;\n    public static from<T extends { [key: string]: DataType } = any>(source: RecordBatchReader<T>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg0): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg2): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg1): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg3): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg4): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg5): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: PromiseLike<RecordBatchReader<T>>): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptions<Struct<T>, TNull>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptionsAsync<Struct<T>, TNull>): Promise<Table<T>>;\n    /** @nocollapse */\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(input?: any) {\n\n        if (!input) { return Table.empty(); }\n\n        if (typeof input === 'object') {\n            let table = isIterable(input['values']) ? tableFromIterable<T, TNull>(input)\n                 : isAsyncIterable(input['values']) ? tableFromAsyncIterable<T, TNull>(input)\n                                                    : null;\n            if (table !== null) { return table; }\n        }\n\n        let reader = RecordBatchReader.from<T>(input) as RecordBatchReader<T> | Promise<RecordBatchReader<T>>;\n\n        if (isPromise<RecordBatchReader<T>>(reader)) {\n            return (async () => await Table.from(await reader))();\n        }\n        if (reader.isSync() && (reader = reader.open())) {\n            return !reader.schema ? Table.empty() : new Table<T>(reader.schema, [...reader]);\n        }\n        return (async (opening) => {\n            const reader = await opening;\n            const schema = reader.schema;\n            const batches: RecordBatch[] = [];\n            if (schema) {\n                for await (let batch of reader) {\n                    batches.push(batch);\n                }\n                return new Table<T>(schema, batches);\n            }\n            return Table.empty();\n        })(reader.open());\n    }\n\n    /** @nocollapse */\n    public static async fromAsync<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArgs): Promise<Table<T>> {\n        return await Table.from<T>(source as any);\n    }\n\n    /** @nocollapse */\n    public static fromStruct<T extends { [key: string]: DataType } = any>(vector: Vector<Struct<T>>) {\n        return Table.new<T>(vector.data.childData as Data<T[keyof T]>[], vector.type.children);\n    }\n\n    /**\n     * @summary Create a new Table from a collection of Columns or Vectors,\n     * with an optional list of names or Fields.\n     *\n     *\n     * `Table.new` accepts an Object of\n     * Columns or Vectors, where the keys will be used as the field names\n     * for the Schema:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new({ i32: i32s, f32: f32s });\n     * assert(table.schema.fields[0].name === 'i32');\n     * ```\n     *\n     * It also accepts a a list of Vectors with an optional list of names or\n     * Fields for the resulting Schema. If the list is omitted or a name is\n     * missing, the numeric index of each Vector will be used as the name:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new([i32s, f32s], ['i32']);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === '1');\n     * ```\n     *\n     * If the supplied arguments are Columns, `Table.new` will infer the Schema\n     * from the Columns:\n     * ```ts\n     * const i32s = Column.new('i32', Int32Vector.from([1, 2, 3]));\n     * const f32s = Column.new('f32', Float32Vector.from([.1, .2, .3]));\n     * const table = Table.new(i32s, f32s);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === 'f32');\n     * ```\n     *\n     * If the supplied Vector or Column lengths are unequal, `Table.new` will\n     * extend the lengths of the shorter Columns, allocating additional bytes\n     * to represent the additional null slots. The memory required to allocate\n     * these additional bitmaps can be computed as:\n     * ```ts\n     * let additionalBytes = 0;\n     * for (let vec in shorter_vectors) {\n     *     additionalBytes += (((longestLength - vec.length) + 63) & ~63) >> 3;\n     * }\n     * ```\n     *\n     * For example, an additional null bitmap for one million null values would require\n     * 125,000 bytes (`((1e6 + 63) & ~63) >> 3`), or approx. `0.11MiB`\n     */\n    public static new<T extends { [key: string]: DataType } = any>(...columns: Columns<T>): Table<T>;\n    public static new<T extends VectorMap = any>(children: T): Table<{ [P in keyof T]: T[P]['type'] }>;\n    public static new<T extends { [key: string]: DataType } = any>(children: ChildData<T>, fields?: Fields<T>): Table<T>;\n    /** @nocollapse */\n    public static new(...cols: any[]) {\n        return new Table(...distributeColumnsIntoRecordBatches(selectColumnArgs(cols)));\n    }\n\n    constructor(batches: RecordBatch<T>[]);\n    constructor(...batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, ...batches: RecordBatch<T>[]);\n    constructor(...args: any[]) {\n\n        let schema: Schema<T> = null!;\n\n        if (args[0] instanceof Schema) { schema = args.shift(); }\n\n        let chunks = selectArgs<RecordBatch<T>>(RecordBatch, args);\n\n        if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n            throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n        }\n\n        chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n\n        super(new Struct(schema.fields), chunks);\n\n        this._schema = schema;\n        this._chunks = chunks;\n    }\n\n    protected _schema: Schema<T>;\n    // List of inner RecordBatches\n    protected _chunks: RecordBatch<T>[];\n    protected _children?: Column<T[keyof T]>[];\n\n    public get schema() { return this._schema; }\n    public get length() { return this._length; }\n    public get chunks() { return this._chunks; }\n    public get numCols() { return this._numChildren; }\n\n    public clone(chunks = this._chunks) {\n        return new Table<T>(this._schema, chunks);\n    }\n\n    public getColumn<R extends keyof T>(name: R): Column<T[R]> {\n        return this.getColumnAt(this.getColumnIndex(name)) as Column<T[R]>;\n    }\n    public getColumnAt<R extends DataType = any>(index: number): Column<R> | null {\n        return this.getChildAt(index);\n    }\n    public getColumnIndex<R extends keyof T>(name: R) {\n        return this._schema.fields.findIndex((f) => f.name === name);\n    }\n    public getChildAt<R extends DataType = any>(index: number): Column<R> | null {\n        if (index < 0 || index >= this.numChildren) { return null; }\n        let field: Field<R>, child: Column<R>;\n        const fields = (this._schema as Schema<any>).fields;\n        const columns = this._children || (this._children = []) as Column[];\n        if (child = columns[index]) { return child as Column<R>; }\n        if (field = fields[index]) {\n            const chunks = this._chunks\n                .map((chunk) => chunk.getChildAt<R>(index))\n                .filter((vec): vec is Vector<R> => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Column<R>(field, chunks));\n            }\n        }\n        return null;\n    }\n\n    // @ts-ignore\n    public serialize(encoding = 'binary', stream = true) {\n        const Writer = !stream\n            ? RecordBatchFileWriter\n            : RecordBatchStreamWriter;\n        return Writer.writeAll(this).toUint8Array(true);\n    }\n    public count(): number {\n        return this._length;\n    }\n    public select<K extends keyof T = any>(...columnNames: K[]) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name as K, i), new Map<K, number>());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)!).filter((x) => x > -1));\n    }\n    public selectAt<K extends T[keyof T] = any>(...columnIndices: number[]) {\n        const schema = this._schema.selectAt<K>(...columnIndices);\n        return new Table(schema, this._chunks.map(({ length, data: { childData } }) => {\n            return new RecordBatch(schema, length, columnIndices.map((i) => childData[i]).filter(Boolean));\n        }));\n    }\n    public assign<R extends { [key: string]: DataType } = any>(other: Table<R>) {\n\n        const fields = this._schema.fields;\n        const [indices, oldToNew] = other.schema.fields.reduce((memo, f2, newIdx) => {\n            const [indices, oldToNew] = memo;\n            const i = fields.findIndex((f) => f.name === f2.name);\n            ~i ? (oldToNew[i] = newIdx) : indices.push(newIdx);\n            return memo;\n        }, [[], []] as number[][]);\n\n        const schema = this._schema.assign(other.schema);\n        const columns = [\n            ...fields.map((_f, i, _fs, j = oldToNew[i]) =>\n                (j === undefined ? this.getColumnAt(i) : other.getColumnAt(j))!),\n            ...indices.map((i) => other.getColumnAt(i)!)\n        ].filter(Boolean) as Column<(T & R)[keyof T | keyof R]>[];\n\n        return new Table<T & R>(...distributeVectorsIntoRecordBatches<any>(schema, columns));\n    }\n}\n\nfunction tableFromIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptions<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return Table.fromStruct(StructVector.from(input as VectorBuilderOptions<Struct<T>, TNull>));\n    }\n    return null;\n}\n\nfunction tableFromAsyncIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptionsAsync<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return StructVector.from(input as VectorBuilderOptionsAsync<Struct<T>, TNull>).then((vector) => Table.fromStruct(vector));\n    }\n    return null;\n}\n"]},"metadata":{},"sourceType":"module"}